import gc
import pickle
import dill
import pandas as pd
import logging

# {'n_estimators': 155, 'min_samples_split': 5, 'max_features': 'sqrt', 'max_depth': 23}
from creme.metrics import Accuracy
from const_models import MODELS

logger = logging.getLogger()
logger.setLevel(logging.INFO)


def get_model(model_name):
    with open(model_name + '.pkl', 'rb') as f:
        model = pickle.load(f)
    return model


def save_model(model_name, model):
    with open(model_name + '.pkl', 'wb') as file:
        dill.dump(model, file)


def fit_one(data, metric, model):
    y = data.pop("HasDetections")
    x = data

    pred = model.predict_one(x)
    model = model.fit_one(x, y)
    metric = metric.update(y, pred)

    del x, y, data
    gc.collect()

    return metric, model


def train(data, model_name):
    metric = Accuracy()
    try:
        model = get_model(model_name)
    except:
        model = MODELS[model_name]

    data = data.dropna()
    logging.info("####### BEGIN TRAINING #######")
    for index, row in data.iterrows():
        metric, model = fit_one(row, metric, model)
        if index % 500 == 0:
            logging.info("INFO] update id: {} - {} accuracy: {}".format(index, model_name, metric))
    logging.info('####### END TRAINING #######')
    logging.info("[INFO] final - {}".format(metric))

    save_model(model_name, model)
    del metric, model, data
    gc.collect()


def train_iteration_model(df, model_name):
    logging.info("begin training iteration model")
    for df in pd.read_csv('data/data2.csv', low_memory=True, chunksize=100_000, nrows=500_000):
        logging.info("train " + str(model_name))
        train(df, model_name)
    del df
    gc.collect()
    return model_name


def retrain_iteration_model(data, model_name):
    train(data, model_name)
    return model_name


def retrain_one_iteration_model(data, model_name):
    metric = Accuracy()
    model = get_model(model_name)
    for index, row in data.iterrows():
        metric, model = fit_one(row, metric, get_model(model_name))
    logging.info("INFO] update {} - accuracy: {}".format(model_name, metric))
    save_model(model_name, model)
    del model, metric, data
    gc.collect()
    return


def make_prediction_iteration_model(data, model_name):
    logging.info("making prediction: " + str(model_name))
    model = get_model(model_name)
    for index, row in data.iterrows():
        res = model.predict_one(row) * 100
        del model, data
        gc.collect()
        return res
